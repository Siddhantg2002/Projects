{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VSfrUl9nFqOP",
        "nihFfM8CFG5h",
        "HrfSaDR2Fyza",
        "g5oA4KO-FAmt",
        "VCVcomoqEy9_",
        "FMxZYy3oww_y",
        "v6TMqY_iw0_v"
      ],
      "authorship_tag": "ABX9TyNJ2f8G55uZae4Iw+2/JML3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siddhantg2002/Projects/blob/main/Text_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP"
      ],
      "metadata": {
        "id": "VSfrUl9nFqOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n",
        "              \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n",
        "              \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\",\n",
        "              \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\",\n",
        "              \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\n",
        "              \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\",\n",
        "              \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\",\n",
        "              \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n",
        "              \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n",
        "              \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n"
      ],
      "metadata": {
        "id": "pnk9s8mK_yUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3SBG14hxHs9",
        "outputId": "b881a7b5-b2c4-45cb-a38d-fce0e8858353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBXe9zlAzkG-",
        "outputId": "08158516-001c-4760-f07c-1b5250857861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 775
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0bPl0BFzlIm",
        "outputId": "4ba8f5be-d719-410f-b09e-7e8af4b648fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 776
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.corpus\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.downloader.download('vader_lexicon')\n",
        "from nltk.tokenize import sent_tokenize\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da_LqURY6hrZ",
        "outputId": "60a7bbd5-f844-400d-ea19-3ad365f419d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk"
      ],
      "metadata": {
        "id": "CH7sa6Co1fCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_text_1 = open('/content/drive/MyDrive/URLS/URL_150.txt',encoding='utf-8').read()\n"
      ],
      "metadata": {
        "id": "HoHPK3GE9KgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_text_1=article_text_1.lower()"
      ],
      "metadata": {
        "id": "4AoabnORz5F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove spaces, punctuations and numbers\n",
        "clean_text_1 = re.sub('[^a-zA-Z]', ' ', article_text_1)\n",
        "clean_text_1 = re.sub('\\s+', ' ', clean_text_1)\n",
        "clean_text_1 = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", clean_text_1)"
      ],
      "metadata": {
        "id": "CFrDt83a4zuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "tokenized_words_1 = clean_text_1.split()\n",
        "print(tokenized_words_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBPS1M3W6fRN",
        "outputId": "b5d0a188-89bc-4e5f-8eee-2abfccf64dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['home', 'what', 'we', 'think', 'challenges', 'and', 'opportunities', 'of', 'big', 'data', 'in', 'healthcare', 'what', 'we', 'thinkhealthcare', 'challenges', 'and', 'opportunities', 'of', 'big', 'data', 'in', 'healthcare', 'by', 'ajay', 'bidyarthy', 'july', 'facebooktwitterpinterestwhatsapp', 'big', 'data', 'to', 'begin', 'with', 'i', 'shall', 'first', 'like', 'to', 'explain', 'what', 'big', 'data', 'is', 'and', 'why', 'it', 'has', 'become', 'so', 'important', 'in', 'our', 'lives', 'big', 'data', 'is', 'simply', 'data', 'but', 'with', 'a', 'huge', 'size', 'data', 'that', 'is', 'not', 'just', 'voluminous', 'but', 'also', 'growing', 'exponentially', 'with', 'time', 'such', 'data', 'sets', 'are', 'so', 'large', 'and', 'complex', 'that', 'it', 'is', 'not', 'possible', 'to', 'store', 'or', 'process', 'them', 'using', 'traditional', 'data', 'management', 'tools', 'so', 'how', 'huge', 'can', 'this', 'data', 'be', 'social', 'media', 'sites', 'like', 'facebook', 'generate', 'more', 'than', 'terabytes', 'of', 'new', 'data', 'every', 'day', 'in', 'the', 'form', 'of', 'photos', 'video', 'uploads', 'text', 'messages', 'etc', 'a', 'single', 'jet', 'engine', 'can', 'generate', 'more', 'than', 'terabytes', 'of', 'data', 'in', 'minutes', 'of', 'flight', 'time', 'with', 'many', 'thousand', 'flights', 'per', 'day', 'generation', 'of', 'data', 'reaches', 'up', 'to', 'many', 'petabytes', 'data', 'contained', 'in', 'these', 'sets', 'are', 'not', 'always', 'structured', 'it', 'can', 'be', 'semi', 'structured', 'or', 'even', 'unstructured', 'when', 'such', 'is', 'the', 'size', 'and', 'dimension', 'of', 'data', 'we', 'can', 'well', 'imagine', 'how', 'complicated', 'it', 'must', 'be', 'to', 'process', 'and', 'analyze', 'it', 'therefore', 'modern', 'methods', 'of', 'data', 'analysis', 'are', 'being', 'developed', 'and', 'used', 'to', 'process', 'the', 'information', 'contained', 'in', 'big', 'data', 'sets', 'opportunities', 'now', 'coming', 'to', 'the', 'opportunities', 'that', 'big', 'data', 'provides', 'they', 'are', 'not', 'just', 'limited', 'to', 'healthcare', 'big', 'data', 'analysis', 'is', 'now', 'a', 'disruptive', 'technology', 'which', 'has', 'intervened', 'into', 'numerous', 'fields', 'and', 'proved', 'its', 'worth', 'healthcare', 'is', 'no', 'exception', 'big', 'data', 'has', 'the', 'potential', 'to', 'change', 'the', 'entire', 'dynamics', 'of', 'the', 'healthcare', 'industry', 'and', 'improve', 'the', 'quality', 'of', 'life', 'of', 'people', 'healthcare', 'industry', 'is', 'a', 'very', 'large', 'and', 'complicated', 'system', 'it', 'involves', 'a', 'lot', 'of', 'risks', 'and', 'always', 'demands', 'better', 'care', 'however', 'when', 'a', 'large', 'number', 'of', 'patients', 'seek', 'emergency', 'care', 'the', 'complications', 'as', 'well', 'as', 'the', 'cost', 'rise', 'exponentially', 'in', 'india', 'many', 'times', 'we', 'even', 'lack', 'sufficient', 'infrastructure', 'to', 'support', 'the', 'patients', 'there', 'is', 'a', 'deficit', 'of', 'beds', 'as', 'well', 'as', 'doctors', 'to', 'provide', 'treatment', 'to', 'the', 'patients', 'for', 'instance', 'when', 'epidemics', 'break', 'out', 'and', 'lives', 'are', 'lost', 'at', 'a', 'very', 'alarming', 'rate', 'we', 'can', 'easily', 'gauge', 'our', 'helplessness', 'however', 'the', 'scenario', 'is', 'certainly', 'improving', 'now', 'with', 'the', 'advent', 'of', 'digitization', 'into', 'the', 'healthcare', 'system', 'healthcare', 'providers', 'or', 'practitioners', 'are', 'now', 'having', 'access', 'to', 'a', 'huge', 'amount', 'of', 'patient', 'health', 'data', 'this', 'healthcare', 'big', 'data', 'can', 'be', 'processed', 'and', 'analyzed', 'to', 'identify', 'patient', 'patterns', 'more', 'quickly', 'and', 'effectively', 'the', 'information', 'obtained', 'can', 'be', 'extremely', 'useful', 'to', 'figure', 'out', 'chronic', 'health', 'issues', 'and', 'provide', 'preventive', 'treatment', 'plans', 'well', 'beforehand', 'so', 'as', 'to', 'curb', 'that', 'disease', 'or', 'disorder', 'from', 'occurring', 'this', 'method', 'is', 'also', 'known', 'as', 'predictive', 'analysis', 'and', 'it', 'is', 'one', 'of', 'the', 'most', 'crucial', 'benefits', 'of', 'big', 'data', 'in', 'healthcare', 'this', 'technology', 'can', 'help', 'the', 'healthcare', 'industry', 'in', 'more', 'ways', 'than', 'we', 'can', 'infer', 'healthcare', 'organizations', 'that', 'have', 'implemented', 'predictive', 'analysis', 'have', 'witnessed', 'a', 'reduction', 'in', 'er', 'visits', 'by', 'providing', 'support', 'and', 'care', 'to', 'patients', 'and', 'decreasing', 'emergency', 'situations', 'apart', 'from', 'reduced', 'er', 'visits', 'and', 'timely', 'treatment', 'there', 'are', 'many', 'other', 'benefits', 'of', 'big', 'data', 'and', 'predictive', 'analysis', 'patients', 'with', 'high', 'risk', 'life', 'threatening', 'issues', 'can', 'be', 'provided', 'with', 'more', 'customized', 'treatment', 'facilities', 'due', 'to', 'lack', 'of', 'data', 'there', 'exists', 'a', 'lack', 'of', 'proper', 'planning', 'in', 'hospitals', 'under', 'or', 'over', 'booking', 'of', 'staff', 'lack', 'of', 'medical', 'equipment', 'medicines', 'and', 'other', 'facilities', 'are', 'a', 'result', 'of', 'inefficient', 'budgeting', 'and', 'ill', 'management', 'of', 'finances', 'using', 'predictive', 'analysis', 'these', 'problems', 'can', 'be', 'solved', 'which', 'will', 'lead', 'to', 'reduced', 'costs', 'and', 'efficient', 'management', 'of', 'finances', 'better', 'staff', 'allocation', 'and', 'admission', 'rate', 'prediction', 'shall', 'facilitate', 'improvement', 'in', 'daily', 'operations', 'of', 'healthcare', 'organizations', 'by', 'using', 'big', 'data', 'the', 'effect', 'of', 'recency', 'bias', 'could', 'be', 'reduced', 'as', 'well', 'when', 'we', 'give', 'more', 'importance', 'to', 'recent', 'events', 'and', 'tend', 'to', 'ignore', 'the', 'effect', 'of', 'the', 'older', 'ones', 'it', 'may', 'lead', 'to', 'incorrect', 'decisions', 'this', 'is', 'known', 'as', 'recency', 'bias', 'big', 'data', 'also', 'helps', 'in', 'preventing', 'fraudulent', 'activities', 'which', 'in', 'turn', 'prevents', 'losses', 'of', 'insurance', 'companies', 'challenges', 'while', 'all', 'of', 'this', 'is', 'changing', 'the', 'healthcare', 'industry', 'for', 'the', 'better', 'it', 'is', 'not', 'that', 'easy', 'to', 'reap', 'the', 'benefits', 'of', 'big', 'data', 'there', 'are', 'a', 'whole', 'lot', 'of', 'challenges', 'and', 'vulnerabilities', 'attached', 'to', 'its', 'implementation', 'one', 'of', 'the', 'biggest', 'challenges', 'is', 'security', 'healthcare', 'big', 'data', 'contains', 'the', 'personal', 'information', 'and', 'health', 'history', 'of', 'patients', 'acts', 'of', 'hacking', 'cyber', 'theft', 'and', 'phishing', 'pose', 'a', 'serious', 'threat', 'to', 'these', 'databases', 'such', 'data', 'could', 'be', 'stolen', 'and', 'sold', 'for', 'huge', 'sums', 'of', 'money', 'protection', 'of', 'the', 'patients', 'privacy', 'hence', 'is', 'a', 'serious', 'challenge', 'to', 'big', 'data', 'implementation', 'also', 'the', 'data', 'would', 'contain', 'external', 'data', 'apart', 'from', 'medical', 'information', 'the', 'organization', 'therefore', 'has', 'to', 'take', 'care', 'of', 'privacy', 'legal', 'compliances', 'and', 'government', 'policies', 'privacy', 'and', 'security', 'of', 'patients', 'have', 'to', 'be', 'given', 'utmost', 'importance', 'and', 'no', 'breach', 'of', 'any', 'kind', 'can', 'be', 'permitted', 'the', 'next', 'challenge', 'is', 'data', 'classification', 'and', 'modeling', 'the', 'size', 'of', 'the', 'data', 'is', 'massive', 'and', 'it', 'is', 'less', 'structured', 'and', 'heterogeneous', 'classifying', 'such', 'massive', 'data', 'to', 'identify', 'relevant', 'information', 'is', 'a', 'big', 'challenge', 'modeling', 'of', 'such', 'unstructured', 'data', 'is', 'equally', 'difficult', 'storage', 'and', 'retrieval', 'is', 'another', 'major', 'challenge', 'huge', 'cloud', 'servers', 'with', 'sufficient', 'space', 'are', 'required', 'to', 'store', 'such', 'voluminous', 'data', 'also', 'the', 'speed', 'should', 'be', 'high', 'so', 'that', 'uploading', 'of', 'data', 'can', 'be', 'done', 'hassle', 'free', 'the', 'way', 'storage', 'is', 'a', 'challenge', 'retrieval', 'also', 'is', 'a', 'matter', 'of', 'concern', 'integrating', 'the', 'data', 'and', 'getting', 'all', 'relevant', 'systems', 'to', 'link', 'each', 'other', 'is', 'a', 'tough', 'job', 'the', 'next', 'challenge', 'is', 'a', 'major', 'one', 'in', 'my', 'opinion', 'finding', 'the', 'right', 'talent', 'who', 'own', 'the', 'expertise', 'to', 'implement', 'this', 'modern', 'technology', 'is', 'an', 'arduous', 'task', 'shortage', 'of', 'required', 'talent', 'is', 'a', 'crisis', 'in', 'the', 'market', 'today', 'even', 'after', 'hiring', 'the', 'right', 'talent', 'it', 'is', 'a', 'challenge', 'to', 'retain', 'them', 'scarce', 'resources', 'like', 'data', 'scientists', 'are', 'hard', 'to', 'find', 'and', 'even', 'harder', 'to', 'retain', 'they', 'are', 'easily', 'poached', 'by', 'competitors', 'a', 'good', 'and', 'efficient', 'compensation', 'strategy', 'conducive', 'work', 'environment', 'high', 'incentives', 'opportunities', 'for', 'career', 'growth', 'and', 'development', 'can', 'be', 'some', 'of', 'the', 'ways', 'of', 'retaining', 'such', 'intellectual', 'talent', 'in', 'a', 'nutshell', 'we', 'can', 'conclude', 'that', 'while', 'big', 'data', 'is', 'a', 'disruptive', 'technology', 'which', 'will', 'bring', 'about', 'landmark', 'changes', 'in', 'healthcare', 'dynamics', 'the', 'challenges', 'and', 'vulnerabilities', 'need', 'to', 'be', 'addressed', 'with', 'the', 'utmost', 'care', 'and', 'sense', 'of', 'responsibility', 'blackcoffer', 'insights', 'subhasmita', 'dey', 'xavier', 'school', 'of', 'human', 'resource', 'management', 'xub', 'tagsdiseasehealthcare', 'systemhigh', 'incentivesmassive', 'datapredictive', 'analysis', 'facebooktwitterpinterestwhatsapp', 'previous', 'articleobstacles', 'to', 'data', 'driven', 'healthcarenext', 'articlebusiness', 'analytics', 'in', 'the', 'healthcare', 'industry', 'ajay', 'bidyarthy', 'related', 'articlesmore', 'from', 'author', 'rise', 'of', 'telemedicine', 'and', 'its', 'impact', 'on', 'livelihood', 'by', 'rise', 'of', 'e', 'health', 'and', 'its', 'impact', 'on', 'humans', 'by', 'the', 'year', 'rise', 'of', 'e', 'health', 'and', 'its', 'impact', 'on', 'humans', 'by', 'the', 'year', 'advertisement', 'most', 'popular', 'insights', 'etl', 'pipeline', 'october', 'coronavirus', 'effect', 'on', 'the', 'hospitality', 'industry', 'april', 'coronavirus', 'the', 'unexpected', 'challenge', 'for', 'the', 'european', 'union', 'march', 'how', 'python', 'became', 'the', 'first', 'choice', 'for', 'data', 'science', 'march', 'load', 'more', 'recommended', 'insights', 'role', 'of', 'big', 'data', 'analytics', 'in', 'banking', 'and', 'finance', 'is', 'perfection', 'the', 'greatest', 'enemy', 'of', 'productivity', 'what', 'analytics', 'it', 'outsourcing', 'engagement', 'model', 'is', 'right', 'for', 'you', 'how', 'to', 'overcome', 'your', 'fear', 'of', 'making', 'mistakes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stopwords\n",
        "final_words_1=[]\n",
        "for word in tokenized_words_1:\n",
        "  if word not in stop_words:\n",
        "    final_words_1.append(word)"
      ],
      "metadata": {
        "id": "f-wAHv80-w5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SCORES"
      ],
      "metadata": {
        "id": "nihFfM8CFG5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_analyse(sentiment_text_1):\n",
        "  score = SentimentIntensityAnalyzer().polarity_scores(sentiment_text_1)\n",
        "\n",
        "  Positive = score['pos']\n",
        "  Negative = score['neg']\n",
        "  Polarity_Score=(Positive-Negative)/((Positive+Negative)+0.000001)\n",
        "\n",
        "  clean_text_1.split()\n",
        "  Total_Words_After_Cleaning=len(clean_text_1.split())\n",
        "  Subjectivity_score=(Positive-Negative)/((Total_Words_After_Cleaning)+0.000001)\n",
        "\n",
        "  print('score:',score)\n",
        "  print('\\n')\n",
        "  print('Polarity Score:',Polarity_Score)\n",
        "  print('\\n')\n",
        "  print('Subjectivity Score: ',Subjectivity_score)\n",
        "\n",
        "\n",
        "sentiment_analyse(clean_text_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bfzaRKRDPun",
        "outputId": "7ecf4e4b-4536-4fb9-d89c-1d5e3fa29a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score: {'neg': 0.087, 'neu': 0.728, 'pos': 0.185, 'compound': 0.9991}\n",
            "\n",
            "\n",
            "Polarity Score: 0.3602927930412021\n",
            "\n",
            "\n",
            "Subjectivity Score:  8.146300907609059e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average Sentence Length/Average Number of Words Per Sentence AND word count\n"
      ],
      "metadata": {
        "id": "HrfSaDR2Fyza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article_text_1.split()\n",
        "total_words=len(article_text_1.split())\n",
        "print(\"Total Number of Words: \",total_words)\n",
        "sentences = sent_tokenize(article_text_1)\n",
        "number_of_sentences=len(sentences)\n",
        "print('Total number of sentences: ',number_of_sentences)\n",
        "Average_Sentence_Length=total_words/number_of_sentences\n",
        "print(\"Average Sentence Length:\",Average_Sentence_Length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJLFwVshKYDq",
        "outputId": "567ae795-10c8-4b5f-e1f1-d3446479eb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Words:  1217\n",
            "Total number of sentences:  69\n",
            "Average Sentence Length: 17.63768115942029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average Word Length\n"
      ],
      "metadata": {
        "id": "g5oA4KO-FAmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in range(0, len(article_text_1)):  \n",
        "    if(article_text_1[i] != ' '):  \n",
        "        count = count + 1;  \n",
        "print('Total number of characters: ',count)\n",
        "print(\"Total Number of Words: \",total_words)\n",
        "Average_word_length=count/total_words\n",
        "print(\"Average word length: \",Average_word_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnjuBSCz1rjr",
        "outputId": "db0eebc5-6a98-470a-86de-2be92ed1446c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters:  6552\n",
            "Total Number of Words:  1217\n",
            "Average word length:  5.3837304847986855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Syllable Count Per Word"
      ],
      "metadata": {
        "id": "VCVcomoqEy9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def syllable_count(word):\n",
        "    word = word.lower()\n",
        "    count = 0\n",
        "    vowels = \"aeiou\"\n",
        "    if word[0] in vowels:\n",
        "        count += 1\n",
        "    for index in range(1, len(word)):\n",
        "        if word[index] in vowels and word[index - 1] not in vowels:\n",
        "            count += 1\n",
        "    if word.endswith(\"e\"):\n",
        "        count -= 1\n",
        "    if count == 0:\n",
        "        count += 1\n",
        "    return count\n",
        "\n",
        "print('Syllable Count Per Word: ',syllable_count(article_text_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbk50gZWEKYp",
        "outputId": "b2ea12a4-71ef-42c0-a01d-ee10603b43a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syllable Count Per Word:  2207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Personal Pronouns"
      ],
      "metadata": {
        "id": "FMxZYy3oww_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_personal_pronouns(text):\n",
        "  pronoun_count = re.compile(r'\\b(I|we|ours|my|mine|(?-i:us))\\b', re.I)\n",
        "  pronouns = pronoun_count.findall(text)\n",
        "  return len(pronouns)\n",
        "print(count_personal_pronouns(article_text_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi1JYLqOuCxD",
        "outputId": "edcb7b7a-0df3-463a-9b2b-c995c4b51bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Percentage of Complex Word , Complex Word Count and Fog Index\n"
      ],
      "metadata": {
        "id": "v6TMqY_iw0_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_complex_words(words_list):\n",
        "  c = 0\n",
        "  for word in words_list:\n",
        "    l = re.findall('(?!e$)[aeiou]+', word, re.I)+re.findall('^[aeiouy]*e$', word, re.I)\n",
        "    if len(l) > 2:\n",
        "      c += 1\n",
        "  return c\n",
        "print('Complex Word Count: ',count_complex_words(tokenized_words_1))\n",
        "print(\"Total Number of Words: \",total_words)\n",
        "print('\\n')\n",
        "POC=count_complex_words(tokenized_words_1)/total_words\n",
        "print('Percentage of complex Words: ',POC)\n",
        "print('\\n')\n",
        "Fog_Index= 0.4 * (Average_Sentence_Length + POC)\n",
        "print('FOG INDEX: ',Fog_Index)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96121PthxYXC",
        "outputId": "7d1f8d56-ec2d-4c66-f0df-1e9ffb641335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complex Word Count:  226\n",
            "Total Number of Words:  1217\n",
            "\n",
            "\n",
            "Percentage of complex Words:  0.18570254724732949\n",
            "\n",
            "\n",
            "FOG INDEX:  7.129353482667049\n"
          ]
        }
      ]
    }
  ]
}